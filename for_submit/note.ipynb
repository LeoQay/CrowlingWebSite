{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from multiprocessing.dummy import Pool, Queue, Manager\n",
    "import urllib.request\n",
    "import requests\n",
    "import gzip\n",
    "import json\n",
    "import codecs\n",
    "import tqdm\n",
    "import bs4\n",
    "import urllib.request as request\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for get urls\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def namer(func, name):\n",
    "    def wrapper(name_):\n",
    "        return func(name_, name)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def cmp_with_name(name_, name):\n",
    "    return name_ == name\n",
    "\n",
    "\n",
    "def naming(name):\n",
    "    return namer(cmp_with_name, name)\n",
    "\n",
    "\n",
    "def has_my_attr(tag, name):\n",
    "    return tag.has_attr(name)\n",
    "\n",
    "\n",
    "def get_names(html):\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    games_tag = soup.find_all(class_=naming('grid-list games-hover-boxes'))[0]\n",
    "    games_tags = games_tag.find_all(namer(has_my_attr, 'data-game-name'))\n",
    "    return [tag['data-game-name'] for tag in games_tags]\n",
    "\n",
    "\n",
    "def fetch_url(url, max_attempts=50):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            req = request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            return request.urlopen(req).read().decode(encoding='utf-8')\n",
    "        except ...:\n",
    "            pass\n",
    "        attempts += 1\n",
    "    raise TimeoutError\n",
    "\n",
    "\n",
    "def fetch_urls():\n",
    "    num = 1\n",
    "    names = []\n",
    "    aim = 300\n",
    "    url = 'https://gg.deals/games/?sort=metascore&type=1&page='\n",
    "    while len(names) < aim:\n",
    "        try:\n",
    "            text = fetch_url(url + str(num))\n",
    "            names += get_names(text)\n",
    "        except TimeoutError:\n",
    "            return num\n",
    "        num += 1\n",
    "    return names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get urls and write to 'urls.txt'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "games = fetch_urls()\n",
    "if isinstance(games, int):\n",
    "    print(games, file=sys.stderr)\n",
    "else:\n",
    "    with open('urls.txt', 'w') as file:\n",
    "        for game in games[:300]:\n",
    "            print('https://gg.deals/game/' + game, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for page processing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "manager = Manager()\n",
    "global_err_stat = manager.dict()\n",
    "\n",
    "\n",
    "def err(stat, what='error'):\n",
    "    url = stat['url']\n",
    "    print(f'Error: url: {url}: with {what}', file=sys.stderr)\n",
    "    if url not in global_err_stat:\n",
    "        global_err_stat[url] = {what: 1}\n",
    "    elif what not in global_err_stat[url]:\n",
    "        global_err_stat[url][what] = 1\n",
    "    else:\n",
    "        global_err_stat[url][what] += 1\n",
    "\n",
    "\n",
    "def namer(func, name):\n",
    "    def wrapper(thing):\n",
    "        return func(thing, name)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def has_attr(tag, name):\n",
    "    return tag is not None and tag.has_attr(name)\n",
    "\n",
    "\n",
    "def consist(name_, name):\n",
    "    return name_ is not None and name_.find(name) != -1\n",
    "\n",
    "\n",
    "def get_tag(start_tag, path):\n",
    "    tag = start_tag\n",
    "    for args, kwargs, pos in path:\n",
    "        if tag is None:\n",
    "            return None\n",
    "        if pos == -1:\n",
    "            tag = tag.find(*args, **kwargs)\n",
    "        else:\n",
    "            tag = tag.find_all(*args, **kwargs)[pos]\n",
    "    return tag\n",
    "\n",
    "\n",
    "def get_name(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'breadcrumbs-widget pjax-inner-replace'}, -1),\n",
    "        (('div',), {'class_': 'container'}, -1),\n",
    "        (('ul',), {'class_': 'breadcrumbs-list'}, -1),\n",
    "        (('li',), {}, 3),\n",
    "        (('span',), {}, -1)\n",
    "    ]\n",
    "    dest = get_tag(soup, path)\n",
    "    if dest is not None:\n",
    "        stat['name'] = dest.get_text()\n",
    "    else:\n",
    "        err(stat, 'name')\n",
    "\n",
    "\n",
    "def get_image(stat, soup):\n",
    "    path = [\n",
    "        (('img',), {}, -1),\n",
    "    ]\n",
    "    tag = get_tag(soup, path)\n",
    "    if tag is not None:\n",
    "        stat['image'] = tag['src']\n",
    "    else:\n",
    "        err(stat, 'image')\n",
    "\n",
    "\n",
    "def get_market_url(stat, soup):\n",
    "    path = [\n",
    "        (('a',), {'class_': 'game-link-widget'}, -1)\n",
    "    ]\n",
    "    tag = get_tag(soup, path)\n",
    "    if tag is None:\n",
    "        err(stat, 'market_url')\n",
    "        return\n",
    "    url = tag['href']\n",
    "    try:\n",
    "        req = request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        res = urllib.request.urlopen(req)\n",
    "    except BaseException:\n",
    "        err(stat, 'market_url')\n",
    "    else:\n",
    "        stat['market_url'] = res.geturl()\n",
    "\n",
    "\n",
    "def get_from_game_info_image(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-image'}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-info-image')\n",
    "        return\n",
    "    get_image(stat, soup)\n",
    "    get_market_url(stat, soup)\n",
    "\n",
    "\n",
    "def get_wishlist_counter(stat, soup):\n",
    "    path = [\n",
    "        ((), {'class_': namer(consist, 'wishlisted-game')}, -1),\n",
    "        (('span',), {'class_': 'user-count'}, -1),\n",
    "        (('span',), {'class_': 'count'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['wishlist_count'] = int(soup.get_text())\n",
    "    else:\n",
    "        err(stat, 'wishlist_count')\n",
    "\n",
    "\n",
    "def get_alert_counter(stat, soup):\n",
    "    path = [\n",
    "        ((), {'class_': namer(consist, 'alerted-game')}, -1),\n",
    "        (('span',), {'class_': 'user-count'}, -1),\n",
    "        (('span',), {'class_': 'count'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['alert_count'] = int(soup.get_text())\n",
    "    else:\n",
    "        err(stat, 'alert_count')\n",
    "\n",
    "\n",
    "def get_own_counter(stat, soup):\n",
    "    path = [\n",
    "        ((), {'class_': namer(consist, 'owned-game')}, -1),\n",
    "        (('span',), {'class_': 'user-count'}, -1),\n",
    "        (('span',), {'class_': 'count'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        try:\n",
    "            stat['owners_count'] = int(soup.get_text())\n",
    "        except BaseException:\n",
    "            err(stat, 'owners_count')\n",
    "    else:\n",
    "        err(stat, 'owners_count')\n",
    "\n",
    "\n",
    "def get_from_game_collection_actions(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-header game-header-container container'}, -1),\n",
    "        ((namer(has_attr, 'data-counters-url'),), {}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-header game-header-container container')\n",
    "        return\n",
    "    get_wishlist_counter(stat, soup)\n",
    "    get_alert_counter(stat, soup)\n",
    "    get_own_counter(stat, soup)\n",
    "\n",
    "\n",
    "def get_release_date(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-details-section game-info-details-section-release'}, -1),\n",
    "        (('p',), {'class_': 'game-info-details-content'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['release_date'] = soup.get_text()\n",
    "    else:\n",
    "        err(stat, 'release_date')\n",
    "\n",
    "\n",
    "def get_developer(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-details-section game-info-details-section-developer'}, -1),\n",
    "        (('p',), {'class_': 'game-info-details-content'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['developer'] = soup.get_text()\n",
    "    else:\n",
    "        err(stat, 'developer')\n",
    "\n",
    "\n",
    "def get_metacritic_score(stat, soup):\n",
    "    path = [\n",
    "        (('span',), {'class_': 'overlay'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['metacritic_score'] = int(soup.get_text())\n",
    "    else:\n",
    "        err(stat, 'metacritic_score')\n",
    "\n",
    "\n",
    "def get_user_score(stat, soup):\n",
    "    path = [\n",
    "        (('span',), {'class_': 'overlay'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is not None:\n",
    "        stat['user_score'] = float(soup.get_text())\n",
    "    else:\n",
    "        err(stat, 'user_score')\n",
    "\n",
    "\n",
    "def get_from_first_score(stat, soup):\n",
    "    soups = soup.find_all('div', class_='score-col')\n",
    "    if len(soups) == 0:\n",
    "        err(stat, 'metacritic_score')\n",
    "        return\n",
    "    get_metacritic_score(stat, soups[0])\n",
    "    if len(soups) == 1:\n",
    "        err(stat, 'user_score')\n",
    "        return\n",
    "    get_user_score(stat, soups[1])\n",
    "\n",
    "\n",
    "def get_from_second_score(stat, soup):\n",
    "    path = [\n",
    "        (('a',), {'class_': 'score-grade'}, -1),\n",
    "        (('span',), {}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'review block')\n",
    "        return\n",
    "    try:\n",
    "        if soup.has_attr('title'):\n",
    "            stat['review_positive_pctg'] = int(soup['title'].split()[0][:-1])\n",
    "        else:\n",
    "            err(stat, 'review_positive_pctg')\n",
    "        text = soup.get_text().split()\n",
    "        stat['review_label'] = ' '.join(text[:-1])\n",
    "        count = ''.join(text[-1].strip()[1:-1].split(','))\n",
    "        stat['review_count'] = int(count)\n",
    "    except BaseException:\n",
    "        err(stat, 'review block')\n",
    "\n",
    "\n",
    "def get_from_reviews(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-details-section game-info-details-section-reviews'}, -1),\n",
    "        (('div',), {'class_': 'game-info-details-content'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'reviews')\n",
    "        return\n",
    "    soups = soup.find_all('div', class_='score')\n",
    "    if len(soups) == 0:\n",
    "        err(stat, 'review, scores')\n",
    "        return\n",
    "    get_from_first_score(stat, soups[0])\n",
    "    if len(soups) == 1:\n",
    "        err(stat, 'review, counts')\n",
    "        return\n",
    "    get_from_second_score(stat, soups[1])\n",
    "\n",
    "\n",
    "def get_platforms(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-details-section game-info-details-section-platforms'}, -1),\n",
    "        (('div',), {'class_': 'platform-link-icons-wrapper'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'platforms')\n",
    "        return\n",
    "    soups = soup.find_all('svg')\n",
    "    result = []\n",
    "    for svg in soups:\n",
    "        if svg.has_attr('title'):\n",
    "            result.append(svg['title'])\n",
    "        else:\n",
    "            err(stat, 'platform title')\n",
    "    stat['platforms'] = result\n",
    "\n",
    "\n",
    "def get_from_game_info_details(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-info-details'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-info-details')\n",
    "        return\n",
    "    get_release_date(stat, soup)\n",
    "    get_developer(stat, soup)\n",
    "    get_from_reviews(stat, soup)\n",
    "    get_platforms(stat, soup)\n",
    "\n",
    "\n",
    "def get_genres(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'id': 'game-info-genres'}, -1),\n",
    "        (('div',), {'class_': 'tags-list badges-container'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'genres')\n",
    "        return\n",
    "    soups = soup.find_all('a')\n",
    "    stat['genres'] = [a.get_text() for a in soups]\n",
    "\n",
    "\n",
    "def get_tags(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'id': 'game-info-tags'}, -1),\n",
    "        (('div',), {}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'tags')\n",
    "        return\n",
    "    soups = soup.find_all('a')\n",
    "    stat['tags'] = [a.get_text() for a in soups]\n",
    "\n",
    "\n",
    "def get_features(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'id': 'game-info-features'}, -1),\n",
    "        (('div',), {}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'features')\n",
    "        return\n",
    "    soups = soup.find_all('a')\n",
    "    stat['features'] = [a.get_text() for a in soups]\n",
    "\n",
    "\n",
    "def get_from_game_offers_col_right(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'col-right'}, -1),\n",
    "        (('div',), {'class_': 'game-info-content shadow-box-big-light'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-offers-col-right')\n",
    "        return\n",
    "    get_from_game_info_details(stat, soup)\n",
    "    get_genres(stat, soup)\n",
    "    get_tags(stat, soup)\n",
    "    get_features(stat, soup)\n",
    "\n",
    "\n",
    "def get_href(hover):\n",
    "    soup = hover.find('a')\n",
    "    if soup is None or not soup.has_attr('href'):\n",
    "        pass\n",
    "    else:\n",
    "        return 'https://gg.deals' + soup['href']\n",
    "\n",
    "\n",
    "def get_dlcs(stat, soup):\n",
    "    path = [\n",
    "        (('section',), {'id': 'game-dlcs'}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'dlcs')\n",
    "        return\n",
    "    soups = soup.find_all('div', class_=namer(consist, 'hoverable-box'))\n",
    "    result = []\n",
    "    for hover in soups:\n",
    "        href = get_href(hover)\n",
    "        if href is not None:\n",
    "            result.append(href)\n",
    "        else:\n",
    "            err(stat, 'dlcs href')\n",
    "    stat['dlcs'] = result\n",
    "\n",
    "\n",
    "def get_packs(stat, soup):\n",
    "    path = [\n",
    "        (('section',), {'id': 'game-packs'}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'packs')\n",
    "        return\n",
    "    soups = soup.find_all('div', class_=namer(consist, 'hoverable-box'))\n",
    "    result = []\n",
    "    for hover in soups:\n",
    "        href = get_href(hover)\n",
    "        if href is not None:\n",
    "            result.append(href)\n",
    "        else:\n",
    "            err(stat, 'packs href')\n",
    "    stat['packs'] = result\n",
    "\n",
    "\n",
    "def get_from_game_offers_col_left(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-section section-row'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-offers-col-left')\n",
    "        return\n",
    "    get_dlcs(stat, soup)\n",
    "    get_packs(stat, soup)\n",
    "\n",
    "\n",
    "def get_from_game_offers(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-section game-offers'}, -1),\n",
    "        (('div',), {'class_': 'container'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-offers')\n",
    "        return\n",
    "    get_from_game_offers_col_right(stat, soup)\n",
    "    get_from_game_offers_col_left(stat, soup)\n",
    "\n",
    "\n",
    "def get_price_history(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-section game-about game-price-history'}, -1),\n",
    "        (('div',), {'class_': 'container'}, -1),\n",
    "        (('div',), {'class_': 'col-left'}, -1),\n",
    "        (('div',), {'class_': 'chart-container'}, -1)\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None or not soup.has_attr('data-with-keyshops-url'):\n",
    "        err(stat, 'price_history')\n",
    "        return\n",
    "    url = soup['data-with-keyshops-url']\n",
    "    n = 0\n",
    "    max_n = 5\n",
    "    while n < max_n:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                'https://gg.deals' + url,\n",
    "                headers={\n",
    "                    'accept': 'application/json',\n",
    "                    'path': url,\n",
    "                    'scheme': 'https',\n",
    "                    'method': 'GET',\n",
    "                    'accept-encoding': 'gzip, deflate, br',\n",
    "                    'authority': 'gg.deals',\n",
    "                    'x-requested-with': 'XMLHttpRequest',\n",
    "                    'accept-language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "                }\n",
    "            )\n",
    "        except BaseException:\n",
    "            n += 1\n",
    "        else:\n",
    "            break\n",
    "    if n == max_n:\n",
    "        err(stat, 'price_history fetch')\n",
    "        return\n",
    "    response = response.json()['chartData']['deals']\n",
    "    for it in response:\n",
    "        it['ts'] = it['x']\n",
    "        it['price'] = it['y']\n",
    "        del it['name']\n",
    "        del it['x']\n",
    "        del it['y']\n",
    "    stat['price_history'] = response\n",
    "\n",
    "\n",
    "def get_from_game_card(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'game-card'}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'game-card')\n",
    "        return\n",
    "    get_from_game_info_image(stat, soup)\n",
    "    get_from_game_collection_actions(stat, soup)\n",
    "    get_from_game_offers(stat, soup)\n",
    "\n",
    "\n",
    "def get_from_main_content_page(stat, soup):\n",
    "    path = [\n",
    "        (('div',), {'class_': 'main-content'}, -1),\n",
    "        (('div',), {'id': 'page'}, -1),\n",
    "    ]\n",
    "    soup = get_tag(soup, path)\n",
    "    if soup is None:\n",
    "        err(stat, 'main-content-page')\n",
    "        return\n",
    "    get_name(stat, soup)\n",
    "    get_from_game_card(stat, soup)\n",
    "\n",
    "\n",
    "def get_page(url, n_attempts=5, t_sleep=0.1):\n",
    "    n = 0\n",
    "    while n < n_attempts:\n",
    "        try:\n",
    "            req = request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            return urllib.request.urlopen(req)\n",
    "        except BaseException:\n",
    "            n += 1\n",
    "            time.sleep(t_sleep)\n",
    "\n",
    "\n",
    "def process_page(url):\n",
    "    res = get_page(url)\n",
    "    if res is None:\n",
    "        err({'url': url}, 'fetch')\n",
    "        return None\n",
    "    data = res.read().decode(encoding='utf-8')\n",
    "    soup = bs4.BeautifulSoup(data, 'html.parser')\n",
    "    stat = {}\n",
    "    soup = soup.html.body\n",
    "    stat['url'] = url\n",
    "    get_from_main_content_page(stat, soup)\n",
    "    get_price_history(stat, soup)\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function of process for multiprocessing\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def process_page_wrapper(i):\n",
    "    file_name = 'data/part_{:05d}.jsonl.gz'.format(i)\n",
    "\n",
    "    with gzip.open(file_name, mode='wb') as f_json:\n",
    "        f_json = codecs.getwriter('utf8')(f_json)\n",
    "\n",
    "        while not queue.empty():\n",
    "            try:\n",
    "                url = queue.get()\n",
    "                record = process_page(url)\n",
    "                record_str = json.dumps(record, ensure_ascii=False)\n",
    "                print(record_str, file=f_json)\n",
    "            except BaseException:\n",
    "                err({'url': url}, 'uncatched')\n",
    "            finally:\n",
    "                with lock:\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process urls from 'urls.txt',\n",
    "saving error stat to 'error_stat.json'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('data')\n",
    "except OSError as e:\n",
    "    pass\n",
    "finally:\n",
    "    os.mkdir('data')\n",
    "\n",
    "queue = Queue()\n",
    "with open('urls.txt', 'r') as file:\n",
    "    for url in file:\n",
    "        queue.put(url.strip())\n",
    "\n",
    "processes = 8\n",
    "\n",
    "with Pool(processes=processes) as pool, tqdm.tqdm(total=queue.qsize()) as pbar:\n",
    "    lock = pbar.get_lock()\n",
    "    pool.map(process_page_wrapper, range(pool._processes))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "with open('error_stat.json', 'w') as file:\n",
    "    print(json.dumps(global_err_stat, sort_keys=True, indent=4), file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}